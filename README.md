# Пример использования C#/REST/SWAGGER
При использовании API часто приходится заниматься следующими задачами:
- Изучение потребностей клиентов. Чем-то пользуются чаще, чем-то другим - реже. Для улучшение качества сервиса необходимо анализировать запросы, которые проходят через API.
- Необходимо отлавливать ошибки и быстро реагировать на них.
- Важно следить за временем ответа на запросы. Если слишком велико - значит нужно искать причину.
- Не стоит говорить о популярности микросервисной архитектуры. Когда микросервисов становится много, бывает сложно установить связи между ними. В данном проекте отсеживаются вызывающая сторона и сервис.
- Кэшировать запросы и ответы.


Для решения поставленных задач используется Elastic Stack. В нашем случае это:
- Elasticsearch - БД, в которой хранятся логи, выполняются запросы, строятся агрегации.
- Logstash - парсинг логов и отправка в Elasticsearch. Можно индексировать напрямую в Elasticsearch из Web API, но в этом случае просядет скорость ответа у клиента. Клиент не должен ждать нашу индексацию, ответ должен быть получен как можно раньше. Запись в файл произойдет быстрее.
- Kibana - графическая оболочка над Elasticsearch.

У Elasticsearch есть два типа текстовых полей: keyword и text. Если проводить аналогию с SQL Server, то это INDEX на текстовый столбец (keyword) и FULLTEX INDEX соответственно (text).
Elasticsearch поддериживает следующие виды типизаций:
- Статическая
- Динамическая
- Шаблонная.
Мы воспользуемся третьим вариантом.
Для этого написан C#-проект ElasticConfigurator, который создает шаблон на стороне Elasticsearch. Суть шаблона такова:
Если название поля заканчивается на _keyword, то полю присвоится keyword. Также предусмотрены text, nested и object.
Отлично, теперь необходимо написать mapping для классов-запросов C#. Для этого делается partial class запроса, в котором описано, как переименовывать поля при сериализации в JSON. В данном проекте используется класс GetCompaniesRequest, который используется для получения списка компаний.
```csharp
	/// <summary>
	///     Запрос на получение списка компаний (Фильтры).
	/// </summary>
	public partial class GetCompaniesRequest
	{
		/// <summary>
		///     Наименование компании.
		/// </summary>
		public string CompanyName { get; set; }

		/// <summary>
		///     Код статуса компании.
		/// </summary>
		public string CompanyStatusCode { get; set; }
	}
```
В отдельном файле создается его вторая часть, в котором описан mapping для сериализатора:
```csharp
	using It = WebApi.Model.Request.GetCompaniesRequest;
	
	public partial class GetCompaniesRequest : ILogSerializable
	{
		private static readonly LogJsonSerializer SERIALIZER;

		static GetCompaniesRequest()
		{
			SERIALIZER = new LogJsonSerializer(contractResolver =>
				contractResolver
					.SetKeyword<It>(it => it.CompanyStatusCode)
					.SetText<It>(it => it.CompanyName)
					.SetIgnore<It>(it => it.JsonSerializer)
			);
		}

		/// <inheritdoc />
		public LogJsonSerializer JsonSerializer { get; } = SERIALIZER;
	}
```

В данном случае мы сообщаем сериализатору, что поле CompanyStatusCode должно иметь тип keyword и переименовано в CompanyStatusCode_Keyword, CompanyName в CompanyName_Text.


## Класс MethodExecutor
Данный класс ползволяет:
- Сохранять запрос в лог (метод SetLogger). Если не вызвать данного метода, логироваться не будет.
- Кэшировать (метод SetCache). Если не вызван метод - кэшироваться не будет.
- Устанавливать информацию об http-соединении (метод SetConnectionInfo). Как и прежде, не вызван - не будет информации об http-соединении, необходимой для потсроения связей между микросервисами.

Можно указать событие, которое необходимо логировать:
- Exception - сохраняется запись в лог, если произошло иссключение.
- Execution - сохраняется запись в лог, если записи не оказалось в кэше и пришлось вызывать метод по получению данных.
- Cache - сохраняется запись в лог, если запись оказалось в кэше и не пришлось вызывать метод по получению данных.

Каждый запрос сохраняется как JSON единой строкой в текстовый файл. В проекте он задается с помощью log4net. Путь к этому текстовому файлу необходимо указать в файлах-конфигурации Logstash. Затем он сам отслеживает изменения и индексирует их в Elasticsearch.
После того как стали повляться записи в индексе, необходимо настроить "Index pattern" в Kibana.
Следующим этапом настроить визуализации в Kibana.

Что бы не мучиться со сборкой и попробовать это дело в действии, можно запустить Docker-compose. Для этого необходимо в PowerShell перейти в папку Scripts и написать
docker-compose up.

В качестве источника данных используется список компаний Великобритании.

Сайт, который использует API (http://localhost:8100), доступен по адресу: http://localhost:8200.
Что бы собрать некоторую метрику, необходимо немного "понажимать".
Kibana dashboard выглядит примерно так:
![Web Site](https://raw.githubusercontent.com/scrappyCoco/RestExample/master/Screens/WebSite.PNG)
![Kibana Dashboard](https://raw.githubusercontent.com/scrappyCoco/RestExample/master/Screens/KibanaDashboard.PNG)
